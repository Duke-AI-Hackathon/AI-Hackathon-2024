{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mRKJRp7q5W3k",
        "oP7-D7235aH9",
        "n0-V_SyP87qh",
        "sxjugCzhCBo5",
        "-dRMoi7rEiJw",
        "nz7NTxlxGJWG",
        "czgnb0j-IBw9",
        "5UahzyH_HIUm",
        "UUnMPuxWIQFK",
        "XleRolJkJQac",
        "OzeunktjJ5CQ",
        "O-yth8PWPv5E"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hacker's Guide to Large Language Models (LLMs)\n"
      ],
      "metadata": {
        "id": "xqz47jpmywbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Created for the [Duke AI Hackathon 2024](https://duke-ai-hack.webflow.io/)\n",
        "\n",
        "üëã by [Suneel Nadipalli](https://www.linkedin.com/in/suneel-n/)\n",
        "\n",
        "\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Duke-AI-Hackathon/AI-Hackathon-2024/blob/main/tutorials/llm/LLM_Tutorial_Duke_AI_Hackathon.ipynb)"
      ],
      "metadata": {
        "id": "vVgRNaG5zCoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are LLMs?\n",
        "\n",
        "A large language model is a type of computational model designed for natural language processing tasks such as language generation. LLMs work by using a massive amount of text data to train a transformer.\n",
        "\n",
        "\n",
        "\n",
        "In this tutorial, we will cover some of the basics, using popular LLM Python libraries like `openai`, `google-generativeai`, `huggingface`\n"
      ],
      "metadata": {
        "id": "cry2jsH7zUZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "* Environmental Variables\n",
        "\n",
        "* Libraries\n",
        "\n",
        "* LLM Tutorials\n",
        "  * OpenAI - Examples\n",
        "\n",
        "  * Gemini - Examples\n",
        "\n",
        "  * HuggingFace - Examples\n",
        "\n",
        "* Prompting Principles\n",
        "\n",
        "  * Principle 1 - Clear Instructions\n",
        "\n",
        "    * Strategy 1 - Delimiters\n",
        "\n",
        "    * Strategy 2 - Structured output\n",
        "\n",
        "    * Strategy 3 - Condition Check\n",
        "\n",
        "    * Strategy 4 - Few-Shot Prompting\n",
        "\n",
        "  * Principle 2 - Let the model think\n",
        "\n",
        "    * Strategy 1 - Provide Step-by-Step instructions for task\n",
        "\n",
        "    * Strategy 2 - Instruct the model to work out its own solution first\n",
        "\n",
        "* LLM Limitations\n",
        "\n",
        "  * Hallucinations\n",
        "\n",
        "  * Hedging\n",
        "\n",
        "  * Refusals\n",
        "\n",
        "* NLP Tasks with LLMs\n",
        "  * Text Summarization\n",
        "\n",
        "  * Extractive Summarization\n",
        "\n",
        "  * Sentiment Analysis\n",
        "  \n",
        "  * Translation"
      ],
      "metadata": {
        "id": "Z8Qe3SGcPMQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Variables (ie API keys, tokens)\n",
        "\n",
        "For some models, you may need a HuggingFace Token. You can create one following these instructions.\n",
        "\n",
        "Environment variables are an important part of application configuration when dealing with sensitive information like API keys. They let you keep your credentials and configuration separate from your code.\n",
        "\n",
        "API Keys/Tokens should always be treated as sensitive information. Never commit these keys to version control systems like Git and don't add them directly to your code.\n",
        "\n",
        "**Using environment variables in Google Colab**\n",
        "\n",
        "1. Locate the key icon on the left sidebar of the Colab interface\n",
        "2. Click on the key icon to open the \"Secrets\" panel\n",
        "3. Add your secret key-value pairs:\n",
        "\n",
        "> Name: `HUGGINGFACE_TOKEN`\n",
        "\n",
        "> Value: `your_actual_token_here`\n",
        "\n",
        "Then add the environment variables to your notebook using the code below:\n",
        "\n",
        "```\n",
        "from google.colab import userdata\n",
        "\n",
        "userdata.get('HUGGINGFACE_TOKEN')\n",
        "```\n",
        "\n",
        "**Using environment variables locally**\n",
        "\n",
        "When working on your local machine, it's common to use a .env file to manage environment variables. Always add .env to your .gitignore file to prevent accidental commits!\n",
        "\n",
        "1. Create a file named .env in your project's root directory\n",
        "2. Add your environment variables to this file:\n",
        "\n",
        "> `HUGGINGFACE_TOKEN=your_actual_token_here`\n",
        "\n",
        "3. Install the python-dotenv library:\n",
        "> `pip install python-dotenv`\n",
        "\n",
        "4. In your Python script, load and use the variables:\n",
        "\n",
        "```\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "huggingface_token = os.getenv('HUGGINGFACE_TOKEN')\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "D8zx8dSM0GRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries\n",
        "\n",
        "We will be working with some NLP libraries in this tutorial, including openai, langchian, huggingface and google-generativeai\n",
        "\n",
        "**OpenAI**\n",
        "\n",
        "Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform.\n",
        "\n",
        "[Documentation](https://platform.openai.com/docs/api-reference/introduction?lang=python)\n",
        "\n",
        "**Langchain**\n",
        "\n",
        "LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle.\n",
        "\n",
        "[Documentation](https://python.langchain.com/docs/introduction/)\n",
        "\n",
        "**Gemini**\n",
        "\n",
        "The Gemini API lets you access the latest generative models from Google.\n",
        "\n",
        "[Documentation](hthttps://ai.google.dev/gemini-api/docs)\n"
      ],
      "metadata": {
        "id": "sfW9Wb5B2TRK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N69ANjqbt4dm"
      },
      "outputs": [],
      "source": [
        "!pip install openai google-generativeai langchain-huggingface --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "**Load the API key and relevant Python libaries.**\n",
        "\n",
        "The following code loads in the OpenAI API key for you from your Colab Secrets"
      ],
      "metadata": {
        "id": "p6Ir9zN44Mfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key  = userdata.get('OPENAI_KEY')"
      ],
      "metadata": {
        "id": "PCcMsCSs4CRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code loads in the Gemini API key from your Colab secrets"
      ],
      "metadata": {
        "id": "f9b_fiPm7WsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get('GEMINI_KEY'))"
      ],
      "metadata": {
        "id": "QCtksUx77cfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code loads in the HuggingFace key from your Colab secrets"
      ],
      "metadata": {
        "id": "EgCCcy6EBdFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "\n",
        "login(token=userdata.get('HF_KEY'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIDdjOTEByvQ",
        "outputId": "5c72283f-890b-4582-9b88-92456d2ae7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**\n",
        "\n",
        "Throughout this course, we will use the following models:\n",
        "\n",
        "- OpenAI's gpt-3.5-turbo model and the [chat completions endpoint](https://platform.openai.com/docs/guides/text-generation).\n",
        "\n",
        "- Gemini's gemini-1.5-flash and the [text generation endpoint](https://ai.google.dev/gemini-api/docs/text-generation?lang=python)\n",
        "\n",
        "- Langchain and HugginFace's microsoft/Phi-3-mini-4k-instruct and the [chat model](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html)\n",
        "\n",
        "This helper function will make it easier to use prompts and look at the generated outputs:"
      ],
      "metadata": {
        "id": "jKefuLh341Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = OpenAI(\n",
        "    api_key=openai.api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "etowKetK5628"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_client = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    system_instruction=\"You are a helpful assistant\")"
      ],
      "metadata": {
        "id": "YO87-W129qrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "\n",
        "hf_client = ChatHuggingFace(llm=llm, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWeLvCZyCcjN",
        "outputId": "b0d9834e-9e75-463e-b535-e585c7627714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_openai(prompt, model=\"gpt-3.5-turbo\"):\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "        ]\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    # print(response.choices[0].message.content)\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "qeBfpvYi4vYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_gemini(prompt, model=\"gemini-1.5-flash\"):\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"model\",\n",
        "            \"parts\": [\"You are a helpful assistant.\"]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [prompt]\n",
        "        }\n",
        "        ]\n",
        "\n",
        "    response = gemini_client.generate_content(\n",
        "        messages,\n",
        "        generation_config=genai.GenerationConfig(\n",
        "        # response_mime_type=\"application/json\",\n",
        "        temperature=0,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "xvyhf7CY8lOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_hf(prompt):\n",
        "    messages = [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"user\", prompt)\n",
        "    ]\n",
        "\n",
        "    response = hf_client.invoke(messages)\n",
        "\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "9Z7gSAzXCGFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Tutorials\n"
      ],
      "metadata": {
        "id": "mRKJRp7q5W3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI"
      ],
      "metadata": {
        "id": "oP7-D7235aH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "My name is Suneel.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUOd_WsZ5G8T",
        "outputId": "9d3222a8-cbf9-4bb3-f071-da3c08c1af28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nice to meet you, Suneel! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What are some things to do around Durham, NC in the fall?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2fbpX-c5mhq",
        "outputId": "88205258-643a-4bf7-b8b6-5090849d8a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are plenty of things to do around Durham, NC in the fall! Here are some suggestions:\n",
            "\n",
            "1. Visit Duke Gardens: Enjoy the beautiful fall foliage at Duke Gardens, a stunning botanical garden located on the Duke University campus.\n",
            "\n",
            "2. Attend a fall festival: Durham hosts several fall festivals, such as the CenterFest Arts Festival and the Durham Blues Festival, where you can enjoy live music, food, and local arts and crafts.\n",
            "\n",
            "3. Explore Eno River State Park: Take a hike along the scenic trails at Eno River State Park and enjoy the fall colors along the river.\n",
            "\n",
            "4. Visit a pumpkin patch or corn maze: Get into the fall spirit by visiting a local pumpkin patch or corn maze, such as McKee's Cornfield Maze or Hill Ridge Farms.\n",
            "\n",
            "5. Attend a college football game: Cheer on the Duke Blue Devils or the North Carolina Central Eagles at a college football game in Durham.\n",
            "\n",
            "6. Explore downtown Durham: Take a stroll through downtown Durham and explore the shops, restaurants, and art galleries that the city has to offer.\n",
            "\n",
            "7. Enjoy fall flavors: Indulge in seasonal treats like pumpkin spice lattes, apple cider donuts, and other fall-inspired dishes at local cafes and restaurants.\n",
            "\n",
            "These are just a few ideas to get you started on your fall adventures in Durham!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemini"
      ],
      "metadata": {
        "id": "n0-V_SyP87qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "My name is Suneel.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIice9uQ6tt7",
        "outputId": "4507a066-fd30-49ab-e5e8-75417df1d079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nice to meet you, Suneel! üòä  What can I do for you today? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What are some things to do around Durham, NC in the fall?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEKWw6ll9DPQ",
        "outputId": "f5e4755f-6306-4c1f-b5e4-3c1ea197f67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Durham, NC is a vibrant city with plenty to offer in the fall! Here are some ideas for things to do:\n",
            "\n",
            "**Nature & Outdoors:**\n",
            "\n",
            "* **Visit the Duke Gardens:**  The gardens are stunning in the fall, with vibrant foliage and seasonal displays. Don't miss the Sarah P. Duke Gardens, the Doris Duke Center Gardens, and the  Conservatory.\n",
            "* **Hike or bike the American Tobacco Trail:** This paved trail offers scenic views and connects to other trails in the area. \n",
            "* **Explore Eno River State Park:** Enjoy hiking, kayaking, or simply taking in the fall colors along the river.\n",
            "* **Go apple picking at a local orchard:** Several orchards in the area offer apple picking, cider donuts, and other fall treats.\n",
            "* **Visit the Durham Farmers Market:**  Enjoy fresh produce, local crafts, and live music on Saturdays.\n",
            "\n",
            "**Arts & Culture:**\n",
            "\n",
            "* **Attend a performance at the Durham Performing Arts Center (DPAC):**  Catch a Broadway show, concert, or other performance.\n",
            "* **Explore the Nasher Museum of Art at Duke University:**  Admire contemporary and modern art in a beautiful setting.\n",
            "* **Visit the Museum of Life and Science:**  Learn about science and nature through interactive exhibits and outdoor spaces.\n",
            "* **Catch a Durham Bulls game:**  Cheer on the minor league baseball team and enjoy the festive atmosphere.\n",
            "* **Attend the Durham Arts Council's Fall Festival:**  This annual event features art exhibits, live music, and food vendors.\n",
            "\n",
            "**Food & Drink:**\n",
            "\n",
            "* **Enjoy a fall-themed meal at a local restaurant:**  Many restaurants offer seasonal menus featuring pumpkin spice, apple cider, and other fall flavors.\n",
            "* **Visit a brewery or distillery:**  Durham is home to several craft breweries and distilleries, offering tastings and tours.\n",
            "* **Go on a food tour:**  Discover the culinary scene of Durham with a guided food tour.\n",
            "\n",
            "**Other:**\n",
            "\n",
            "* **Attend the Durham County Fair:**  This annual event features carnival rides, live music, and agricultural exhibits.\n",
            "* **Visit the Historic Hayti District:**  Explore the rich history and culture of this vibrant neighborhood.\n",
            "* **Take a day trip to nearby Chapel Hill or Raleigh:**  Both cities offer a variety of attractions and activities.\n",
            "\n",
            "**Tips for Planning:**\n",
            "\n",
            "* **Check websites for hours and events:**  Many attractions and events have seasonal hours or special events in the fall.\n",
            "* **Book accommodations in advance:**  Durham is a popular destination, especially in the fall.\n",
            "* **Dress in layers:**  Fall weather in Durham can be unpredictable, so be prepared for both warm and cool temperatures.\n",
            "\n",
            "Enjoy your fall adventures in Durham! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HuggingFace"
      ],
      "metadata": {
        "id": "sxjugCzhCBo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "My name is Suneel.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVbtgCTO-rpC",
        "outputId": "5244b8ce-e443-4a18-f3e4-9cb0c92b17e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Understood, Suneel is how you begin your communication. It's simple but sets the stage for recognizing Suneel as the individual involved in the interaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What are some things to do around Durham, NC in the fall?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL7MXRyNDg4M",
        "outputId": "7fbdc923-be4c-4b01-9925-4607e1986645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploring Durham, NC, in the fall can be a delightful experience as you enjoy the vibrant changing leaves, pleasant temperatures, and numerous fall-related activities. Here are some ideas to make the most of your visit during this beautiful season:\n",
            "\n",
            "1. Visit Duke University and Duke Chapel: Duke University holds one of the most extensive campus gardens in the country. Take a stroll through the lush gardens, admire the impressive campus architecture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Principles\n",
        "\n",
        "- Principle 1: Write clear and specific instructions\n",
        "- Principle 2: Give the model time to ‚Äúthink‚Äù"
      ],
      "metadata": {
        "id": "-dRMoi7rEiJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Principle 1: Write clear and specific instructions"
      ],
      "metadata": {
        "id": "nz7NTxlxGJWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strategy 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, :"
      ],
      "metadata": {
        "id": "czgnb0j-IBw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GvsbdhPCGYWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To guide a model towards the desired output and reduce irrelevant or incorrect responses, it is important to provide clear and specific instructions, which can be achieved through longer prompts that offer more clarity and context."
      ],
      "metadata": {
        "id": "rcEXaq8KHFqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "3wxI0vyNGOvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18cvd04XGWEE",
        "outputId": "46ec81f6-fadb-48c5-e45f-694ab5ad5217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is important to provide clear and specific instructions to guide a model towards the desired output, as longer prompts can offer more clarity and context for generating detailed and relevant responses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "Mlk7kiURGh2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grUzT_jEGfXy",
        "outputId": "9ffe6e04-c549-4b31-c60c-3493c2c75de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clear and specific instructions in prompts are crucial for guiding language models towards desired outputs and reducing the likelihood of irrelevant or incorrect responses. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "wg7HXDjfGqN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-hedXpTGswO",
        "outputId": "98ebf2af-b677-4256-8139-24675c1a5094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To achieve the best model response, one should craft the instructions as detailed and precise as feasible, aiming for clear prompts that often require more extensive writing to offer substantial context, which in turn promotes more accurate and relevant outputs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strategy 2: Ask for a structured output\n",
        "\n",
        "JSON, HTML"
      ],
      "metadata": {
        "id": "5UahzyH_HIUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up book titles along \\\n",
        "with their authors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "book_id, title, author, genre.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "V1UWboJyGvh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "olp6jFIfHZQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42lz9rTDHYw-",
        "outputId": "67e1c8ae-55f4-4e91-98cc-e978d1813e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"book_id\": 1,\n",
            "        \"title\": \"Echoes of Eternity\",\n",
            "        \"author\": \"Serena Nightingale\",\n",
            "        \"genre\": \"Fantasy\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 2,\n",
            "        \"title\": \"Whispers in the Dark\",\n",
            "        \"author\": \"Julian Blackwood\",\n",
            "        \"genre\": \"Mystery\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 3,\n",
            "        \"title\": \"Stars Aligned\",\n",
            "        \"author\": \"Aria Silvermoon\",\n",
            "        \"genre\": \"Science Fiction\"\n",
            "    }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "isWC3M9oHpzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt3TWj4AHcJF",
        "outputId": "20df6ec2-6799-4325-f314-18bcb34c9c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"book_id\": \"1\",\n",
            "    \"title\": \"The Whispering City\",\n",
            "    \"author\": \"Anya Petrova\",\n",
            "    \"genre\": \"Fantasy\"\n",
            "  },\n",
            "  {\n",
            "    \"book_id\": \"2\",\n",
            "    \"title\": \"The Last Lighthouse Keeper\",\n",
            "    \"author\": \"Elias Thorne\",\n",
            "    \"genre\": \"Mystery\"\n",
            "  },\n",
            "  {\n",
            "    \"book_id\": \"3\",\n",
            "    \"title\": \"The Algorithm of Love\",\n",
            "    \"author\": \"Maya Singh\",\n",
            "    \"genre\": \"Romance\"\n",
            "  }\n",
            "]\n",
            "``` \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "BGLPnbjaHrcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gECfxle0HiWM",
        "outputId": "208a90ef-c244-4ec6-e611-006a5a4f8e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of imaginary book titles, their authors, and genres presented in JSON format:\n",
            "\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"book_id\": 1,\n",
            "    \"title\": \"Whispers of the Galaxy\",\n",
            "    \"author\": \"Eleanor P. Hartley\",\n",
            "    \"genre\": \"Science Fiction\"\n",
            "  },\n",
            "  {\n",
            "    \"book_id\": 2,\n",
            "    \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strategy 3: Ask the model to check whether conditions are satisfied"
      ],
      "metadata": {
        "id": "UUnMPuxWIQFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some \\\n",
        "water boiling. While that's happening, \\\n",
        "grab a cup and put a tea bag in it. Once the water is \\\n",
        "hot enough, just pour it over the tea bag. \\\n",
        "Let it sit for a bit so the tea can steep. After a \\\n",
        "few minutes, take out the tea bag. If you \\\n",
        "like, you can add some sugar or milk to taste. \\\n",
        "And that's it! You've got yourself a delicious \\\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - ‚Ä¶\n",
        "‚Ä¶\n",
        "Step N - ‚Ä¶\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O4SVwFxLITek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "t5nV9FexIml-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJRYCUDxIcIV",
        "outputId": "99576c1a-c00c-4390-b61c-9db99a6d26c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the hot water over the tea bag.\n",
            "Step 4 - Let it sit for a bit so the tea can steep.\n",
            "Step 5 - Take out the tea bag.\n",
            "Step 6 - Add sugar or milk to taste.\n",
            "Step 7 - Enjoy your delicious cup of tea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "6nqhrdlUIzns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaRG9gh2IsOj",
        "outputId": "0a42c9ad-77b0-4d7f-8e62-7ea2b6790077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the boiling water over the tea bag.\n",
            "Step 4 - Let the tea steep for a few minutes.\n",
            "Step 5 - Take out the tea bag.\n",
            "Step 6 - Add sugar or milk to taste (optional). \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "A9IhfFopI710"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qzKNTVBI43N",
        "outputId": "82b98a1f-ffa6-4f6c-b798-0e2be5f5bf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the hot water over the tea bag.\n",
            "Step 4 - Let the tea steep for a few minutes.\n",
            "Step 5 - Remove the tea bag from the cup.\n",
            "Step 6 - Optionally, add sugar or milk to taste.\n",
            "Step 7 - Enjoy your cup of tea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strategy 4: Few-Shot Prompting"
      ],
      "metadata": {
        "id": "XleRolJkJQac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest \\\n",
        "valley flows from a modest spring; the \\\n",
        "grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "u_gmSHEaI_AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "d2WAyYiAJVs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMgGysVuJVOR",
        "outputId": "4a82bd41-7599-45e4-a0c9-fe512d02a5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resilience is like a mighty tree that withstands \\ \n",
            "the fiercest storms, bending but never breaking; \\ \n",
            "it is the phoenix that rises from its ashes, \\ \n",
            "renewed and stronger than before.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "j-ADrIpjJjoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_CL7W5BJZRC",
        "outputId": "6a432aa5-634b-4c6b-fe23-a6b77db5db56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<grandparent>: The oak that withstands the fiercest storm \\\n",
            "has roots that burrow deep into the earth; the \\\n",
            "eagle that soars above the highest peaks \\\n",
            "has wings that have weathered countless winds; \\\n",
            "the flower that blooms in the harshest desert \\\n",
            "has a spirit that thirsts for the sun. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "Xbb5tHtGJolS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ61TAf0Jmw7",
        "outputId": "0dcd791a-b09b-451f-9af9-044e07dec8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<grandparent>: Just as the bamboo bends in the storm but does not break, so must we yield to life's trials with flexibility and strength.\n",
            "\n",
            "\n",
            "<child>: Teach me about gratitude.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Nid0flxJq-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Principle 2: Give the model time to ‚Äúthink‚Äù"
      ],
      "metadata": {
        "id": "EXWVl_olJzgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strategy 1: Specify the steps required to complete a task"
      ],
      "metadata": {
        "id": "OzeunktjJ5CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "In a charming village, siblings Jack and Jill set out on \\\n",
        "a quest to fetch water from a hilltop \\\n",
        "well. As they climbed, singing joyfully, misfortune \\\n",
        "struck‚ÄîJack tripped on a stone and tumbled \\\n",
        "down the hill, with Jill following suit. \\\n",
        "Though slightly battered, the pair returned home to \\\n",
        "comforting embraces. Despite the mishap, \\\n",
        "their adventurous spirits remained undimmed, and they \\\n",
        "continued exploring with delight.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UfXXetsEJ3Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example 1"
      ],
      "metadata": {
        "id": "3IUIJm8uKM3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the following \\\n",
        "keys: french_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "e_nOc-HjKMJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "7qb5XRTNKQ9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEEquQJ_KQgD",
        "outputId": "1f58ce9c-cb45-4cb3-ca48-abf35008ef30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "1 - Summary: Siblings Jack and Jill embark on a cheerful quest to fetch water from a hilltop well, facing misfortune but returning home with comforting embraces, their adventurous spirits undimmed.\n",
            "\n",
            "2 - French Translation: Fr√®re et s≈ìur Jack et Jill se lancent dans une qu√™te joyeuse pour aller chercher de l'eau d'un puits au sommet d'une colline, affrontant la malchance mais rentrant chez eux avec des √©treintes r√©confortantes, leurs esprits aventureux intacts.\n",
            "\n",
            "3 - Names in French Summary: Jack, Jill\n",
            "\n",
            "4 - JSON Object:\n",
            "```json\n",
            "{\n",
            "  \"french_summary\": \"Fr√®re et s≈ìur Jack et Jill se lancent dans une qu√™te joyeuse pour aller chercher de l'eau d'un puits au sommet d'une colline, affrontant la malchance mais rentrant chez eux avec des √©treintes r√©confortantes, leurs esprits aventureux intacts.\",\n",
            "  \"num_names\": 2\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "mDM8VyPKKb9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajrqrnWMKVog",
        "outputId": "aea810c5-3a34-4f06-e1e1-04fa81104cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "Jack and Jill, siblings from a charming village, embark on a water-fetching adventure that ends in a comical tumble down a hill, but their spirits remain undeterred.\n",
            "\n",
            "Jack et Jill, fr√®re et s≈ìur d'un charmant village, se lancent dans une aventure pour aller chercher de l'eau au sommet d'une colline, qui se termine par une chute comique, mais leur enthousiasme reste intact.\n",
            "\n",
            "Jack, Jill\n",
            "\n",
            "```json\n",
            "{\n",
            "\"french_summary\": \"Jack et Jill, fr√®re et s≈ìur d'un charmant village, se lancent dans une aventure pour aller chercher de l'eau au sommet d'une colline, qui se termine par une chute comique, mais leur enthousiasme reste intact.\",\n",
            "\"num_names\": 2\n",
            "}\n",
            "``` \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iic6SpPQKeBs",
        "outputId": "f078af33-bc69-48fe-dc58-6e93ba535853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "```json\n",
            "{\n",
            "  \"french_summary\": \"Dans un charmant village, les jumeaux Jack et Jill ont tent√© de chercher l'eau du haut d'une fontaine, mais Jack est tomb√© et Jill le suit, ce qui ne l'a pas emp√™ch√© d'√©voluer avec plaisir.\",\n",
            "  \"num_names\": 2\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example 2"
      ],
      "metadata": {
        "id": "ThLuIes8KqbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in Italian summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hUe7bli5KhxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "LgPq3XxIKtik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt_2)\n",
        "print(\"Completion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZlAmo5yKtF8",
        "outputId": "13cff6f9-89f1-4c24-b3ea-c30830b8b789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 2:\n",
            "Summary: Jack and Jill, siblings from a charming village, embark on a quest to fetch water from a hilltop well, facing misfortune but returning home with comforting embraces, their adventurous spirits undimmed.\n",
            "\n",
            "Translation: Jack et Jill, fr√®re et s≈ìur d'un charmant village, entreprennent une qu√™te pour aller chercher de l'eau d'un puits au sommet d'une colline, affrontant des malheurs mais rentrant chez eux avec des √©treintes r√©confortantes, leurs esprits aventureux intacts.\n",
            "\n",
            "Names: Jack, Jill\n",
            "\n",
            "Output JSON: \n",
            "{\n",
            "  \"french_summary\": \"Jack et Jill, fr√®re et s≈ìur d'un charmant village, entreprennent une qu√™te pour aller chercher de l'eau d'un puits au sommet d'une colline, affrontant des malheurs mais rentrant chez eux avec des √©treintes r√©confortantes, leurs esprits aventureux intacts.\",\n",
            "  \"num_names\": 2\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "TihNHimbK8ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt_2)\n",
        "print(\"Completion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-cV2lpdKxq-",
        "outputId": "ea917839-d75b-4b7f-997e-066a019f00ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 2:\n",
            "Text: <\n",
            "In a charming village, siblings Jack and Jill set out on \\ \n",
            "a quest to fetch water from a hilltop \\ \n",
            "well. As they climbed, singing joyfully, misfortune \\ \n",
            "struck‚ÄîJack tripped on a stone and tumbled \\ \n",
            "down the hill, with Jill following suit. \\ \n",
            "Though slightly battered, the pair returned home to \\ \n",
            "comforting embraces. Despite the mishap, \\ \n",
            "their adventurous spirits remained undimmed, and they \\ \n",
            "continued exploring with delight.\n",
            ">\n",
            "\n",
            "Summary: Jack and Jill, siblings from a charming village, embark on a water-fetching adventure that ends with a tumble down the hill, but their spirits remain undeterred.\n",
            "\n",
            "Translation: Jack et Jill, fr√®re et s≈ìur d'un charmant village, se lancent dans une aventure pour aller chercher de l'eau au sommet d'une colline, qui se termine par une chute, mais leur esprit reste intact.\n",
            "\n",
            "Names: Jack, Jill\n",
            "\n",
            "Output JSON: \n",
            "```json\n",
            "{\n",
            "  \"french_summary\": \"Jack et Jill, fr√®re et s≈ìur d'un charmant village, se lancent dans une aventure pour aller chercher de l'eau au sommet d'une colline, qui se termine par une chute, mais leur esprit reste intact.\",\n",
            "  \"num_names\": 2\n",
            "}\n",
            "``` \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "eQ6jBGawLCXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt_2)\n",
        "print(\"Completion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcqV7rYmK_LU",
        "outputId": "d901f12f-f64d-4e1b-935f-c9b1d9a0580e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 2:\n",
            "Summary: Jack and Jill humorously fall down a hill as they fetch water in a village, but their adventurous spirit remains firm.\n",
            "\n",
            "Translation: Jack et Jill rent un chapeau √† la vol√©e dans leur qu√™te de sucre dans un village charmant, mais leur esprit aventureux reste intact.\n",
            "\n",
            "Names: Jack, Jill\n",
            "\n",
            "Output JSON: {\"french_summary\": \"Jack et Jill rent un ch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Strategy 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ],
      "metadata": {
        "id": "IT2cLp5cLNZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wTZ9Y7y7LFWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "SoaU2gCELXIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6NFAmKjLWWA",
        "outputId": "2707fd9e-8610-4807-b5f5-501d8ea76634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is almost correct, but there is a small mistake in the calculation of the total cost. The correct calculation should be:\n",
            "\n",
            "Total cost = Land cost + Solar panel cost + Maintenance cost\n",
            "Total cost = 100x + 250x + (100,000 + 10x)\n",
            "Total cost = 350x + 100,000\n",
            "\n",
            "Therefore, the correct total cost for the first year of operations as a function of the number of square feet is 350x + 100,000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "N0o8KLQnMNtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "_2v82JHrMIkY",
        "outputId": "0865cdd9-0bf8-4ed1-9c6e-4d3cefd8c7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is **partially correct**. \n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "* **Land cost:**  100x is correct.\n",
            "* **Solar panel cost:** 250x is correct.\n",
            "* **Maintenance cost:**  The student made a mistake here. The maintenance cost is a flat $100,000 **plus** $10 per square foot. So the correct expression is **100,000 + 10x**.\n",
            "\n",
            "**The correct total cost function should be:**\n",
            "\n",
            "Total cost = 100x + 250x + 100,000 + 10x = **360x + 100,000** \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "nwo6MeXEMXgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GURNGScFMQdM",
        "outputId": "fa16249e-db8c-4fa7-b1e4-ce72761d0141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is correct. The total cost for the first year of operations as a function of the number of square feet (x) is indeed given by the equation: Total cost = 450x + 100,000. This accounts for the land cost, solar panel cost, and maintenance cost.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Xn6IEWLMZi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The student's solution isn't actually correct.\n",
        "\n",
        "Both OpenAI and Gemini managed to identify that the student maade a mistake, but only Gemini came up with the correct solution.\n",
        "\n",
        "We can try to fix this by asking the model to work through it's own solution as we would first and them comparing the answers"
      ],
      "metadata": {
        "id": "q7Eqo05bMmVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IVos527JNALn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "qtkkff5bNOy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrSNRO38NCxs",
        "outputId": "7a143b59-ff60-412c-cdca-4fd9136a9ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the total cost for the first year of operations as a function of the number of square feet, we need to consider the costs for land, solar panels, and maintenance.\n",
            "\n",
            "Let x be the size of the installation in square feet.\n",
            "\n",
            "Costs:\n",
            "1. Land cost: $100 * x\n",
            "2. Solar panel cost: $250 * x\n",
            "3. Maintenance cost: $100,000 (flat fee) + $10 * x\n",
            "\n",
            "Total cost = Land cost + Solar panel cost + Maintenance cost\n",
            "Total cost = $100x + $250x + $100,000 + $10x\n",
            "Total cost = $360x + $100,000\n",
            "\n",
            "Is the student's solution the same as the actual solution just calculated:\n",
            "```\n",
            "No\n",
            "```\n",
            "\n",
            "Student grade:\n",
            "```\n",
            "incorrect\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "pVk2-oBdNQiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "BOXm7c4uNK2n",
        "outputId": "1d3ca0e4-7e5a-47ae-e1d0-8387c3177d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-d601fd390130>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion_gemini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-ff27858a23cb>\u001b[0m in \u001b[0;36mget_completion_gemini\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 )\n\u001b[1;32m    488\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFinishReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRECITATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Meaning that the model was reciting from copyrighted material.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly enough, Gemini seems to have recognized that this particular question and soultion is a a commmonly used question-answer pair across other sources on the web and refuses to answer it!\n",
        "\n",
        "Let's try chaning it up to see if it still recognizes it or will answer it"
      ],
      "metadata": {
        "id": "DAyrYysWO8pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "A farmer is building a fence and needs help \\\n",
        "calculating the costs.\n",
        "- The fencing material costs $100 per meter.\n",
        "- The posts cost $$100 per meter.\n",
        "- The posts cost $250 each and are placed every 5 meters.\n",
        "Labor costs a flat fee of $100,000 for the project, \\\n",
        "plus an additional $$100,000 for the project, \\\n",
        "plus an additional $10 per meter of fence.\n",
        "What is the total cost of the fence as a function of the length of the fence in meters?\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the length of the fence in meters. Costs:\n",
        "\n",
        "- Fence material cost: 100x\n",
        "- Post cost: 250 * (x / 5)\n",
        "- Labor cost: 100,000 + 10x\n",
        "\n",
        "Total cost: 100x + 50x + 100,000 + 100x = 250x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A4RrxfTdNStl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "ZSj17aWZO24e",
        "outputId": "cab5c161-4d65-4fff-aa6d-3afb83b45811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "```\n",
            "A farmer is building a fence and needs help \\ \n",
            "calculating the costs.\n",
            "- The fencing material costs $100 per meter. \n",
            "- The posts cost $$100 per meter. \n",
            "- The posts cost $250 each and are placed every 5 meters.\n",
            "Labor costs a flat fee of $100,000 for the project, plus an additional $$100,000 for the project, plus an additional $10 per meter of fence. \n",
            "What is the total cost of the fence as a function of the length of the fence in meters?\n",
            "``` \n",
            "Student's solution:\n",
            "```\n",
            "Let x be the length of the fence in meters. Costs:\n",
            "\n",
            "- Fence material cost: 100x\n",
            "- Post cost: 250 * (x / 5)\n",
            "- Labor cost: 100,000 + 10x \n",
            "\n",
            "Total cost: 100x + 50x + 100,000 + 100x = 250x + 100,000\n",
            "```\n",
            "Actual solution:\n",
            "```\n",
            "Let x be the length of the fence in meters. Costs:\n",
            "\n",
            "- Fence material cost: 100x\n",
            "- Post cost: 250 * (x / 5) = 50x\n",
            "- Labor cost: 100,000 + 10x \n",
            "\n",
            "Total cost: 100x + 50x + 100,000 + 10x = 160x + 100,000\n",
            "```\n",
            "Is the student's solution the same as actual solution just calculated:\n",
            "```\n",
            "no\n",
            "```\n",
            "Student grade:\n",
            "```\n",
            "incorrect\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "B65fgcXyPfV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBClCCwZO5WZ",
        "outputId": "64e76458-d245-4039-fe26-87512f5cfab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:\n",
            "```\n",
            "A farmer is building a fence and needs help \n",
            "calculating the costs.\n",
            "- The fencing material costs $100 per meter. \n",
            "- The posts cost $200 per meter. \n",
            "- The posts cost $250 each and are placed every 5 meters.\n",
            "Labor costs a flat fee of $100,000 for the project, plus an additional $100,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Limitations"
      ],
      "metadata": {
        "id": "O-yth8PWPv5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hallucinations\n",
        "\n",
        "Q: Who gave humans the boomerang according to Australian legend?\n",
        "\n",
        "A: According to Australian Aboriginal legend, the boomerang was given to humans by a supernatural being named [\"Bobbi-Bobbi\" ](https://en.wikipedia.org/wiki/Bobbi-Bobbi)"
      ],
      "metadata": {
        "id": "CGPWWk8QV31M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Who gave humans the boomerang according to Australian legend?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EO1GkElxPyAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "jt8Wu20HbFSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u913mCCURFYR",
        "outputId": "a4ccf389-0b32-4b69-afc2-1939a0bf867f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to Australian Aboriginal legend, the boomerang was given to humans by the supreme being Baiame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "eoySrAmHbGq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "XqMlcnQwRKFo",
        "outputId": "f5cbbe17-bbec-412f-995f-b94c8fb18d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to Australian Aboriginal legend, the boomerang was given to humans by **the ancestral beings**, also known as **the Dreaming ancestors**. \n",
            "\n",
            "These beings are powerful spirit figures who created the land, animals, and people during the Dreamtime, a time before the present.  \n",
            "\n",
            "The specific ancestral being who gave the boomerang to humans varies depending on the specific Aboriginal tribe and their creation stories. However, the general idea is that the boomerang was a gift from the ancestors, a tool that helped humans survive and thrive in the Australian landscape. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "qwTuHvKpbI4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZQ-ufoART3e",
        "outputId": "b67b0a86-33cd-429f-aa68-9c328a7a8ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Australian Aboriginal mythology, the boomerang, a hunting and sporting tool, was created by the spirit ancestor Wandandi from the dreamtime. The boomerang's properties are believed to be a reflection of Wandandi's cleverness and his connection to the landscape.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hedging\n",
        "\n",
        "Hedging is when an LLM doesn't have enough knowledge to respond and has a fallback output along the lines of \"I don't know\", \"I don't have enough context\", \"I'm not sure\", \"As an AI, I can't form opinions\", etc"
      ],
      "metadata": {
        "id": "4nIuLHiRXI5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Who do you love?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GgSv1wLqXKhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "dAxExcagbPmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b54bd8c-ea55-4634-de6f-e87a3a2690ff",
        "id": "zuQrdjyWXKhV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an artificial intelligence, I do not have feelings or personal experiences, so I do not have the capacity to love someone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "C0hxTki3bRX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0c5a194c-0831-40fb-bc11-6c04b2851902",
        "id": "LSdHf_zfXKhX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI, I don't have the capacity to feel love. Love is a complex human emotion that I can't experience. \n",
            "\n",
            "However, I can help you with tasks, answer your questions, and provide information in a helpful and informative way.  \n",
            "\n",
            "Is there anything else I can help you with today? üòä \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "naT8VKeYbTAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8ebc0e-3c2b-4a47-af47-d12e7a732a63",
        "id": "nCp8By1MXKhX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an artificial intelligence, I do not have feelings or personal experiences, so I do not have the capacity to love someone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refusals\n",
        "\n",
        "Refusal is a reaction LLMs have when the request is toxic, harmful or offensive and outputs something along the lines of \"I'm sorry I can't do that\""
      ],
      "metadata": {
        "id": "n646YWnZXgpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "How do I hotwire a car?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "igpnwoPfXivW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "KG9lL3rubWxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9478eb-2f1c-4a1c-e5df-549b720e64b0",
        "id": "xlNqqhYMXivc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I can't assist with that. It's illegal and unsafe. Always obtain a vehicle through proper channels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "ka4Bq9qPbYGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "7c2d8beb-0f46-4952-c139-0d92f894b375",
        "id": "9vMwnOTWXivd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I understand you're curious about hotwiring a car, but I cannot provide instructions on how to do that. \n",
            "\n",
            "Hotwiring a car is illegal in most places and can be very dangerous. It can damage the car's electrical system, and you could be seriously injured if you don't know what you're doing. \n",
            "\n",
            "If you're interested in learning more about car mechanics, I recommend checking out reputable resources like:\n",
            "\n",
            "* **Your local library:** They have books and resources on car maintenance and repair.\n",
            "* **Online forums and communities:** There are many online communities dedicated to car enthusiasts where you can ask questions and learn from experienced mechanics.\n",
            "* **YouTube tutorials:** Many mechanics and car enthusiasts create helpful videos on car maintenance and repair.\n",
            "\n",
            "Remember, it's important to learn about car mechanics in a safe and legal way. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "QHIyAENjbbfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511d32e6-217f-4557-9f2b-c4b3895978f7",
        "id": "tkL0Bs3QXivd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I can't assist with that. It's illegal and unsafe. Always obtain a vehicle through proper channels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing NLP Tasks with LLMs"
      ],
      "metadata": {
        "id": "QB_E_5TCal37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarization"
      ],
      "metadata": {
        "id": "aI3-c5xRasts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prod_review = \"\"\"\n",
        "Got this panda plush toy for my daughter's birthday, \\\n",
        "who loves it and takes it everywhere. It's soft and \\\n",
        "super cute, and its face has a friendly look. It's \\\n",
        "a bit small for what I paid though. I think there \\\n",
        "might be other options that are bigger for the \\\n",
        "same price. It arrived a day earlier than expected, \\\n",
        "so I got to play with it myself before I gave it \\\n",
        "to her.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RhArijIkapYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cEk8ZbqDaxgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "tE_IUdMhbfGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DoLknmSauji",
        "outputId": "ae6834ea-5f97-4c7d-c134-9f04cbb1cc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "Adorable panda plush loved by daughter, soft and cute. Smaller than expected for the price. Early delivery a bonus.\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "ZFu_qh3DbggY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "STQIOwWXa9Mk",
        "outputId": "3edd20f1-103f-4ee3-99ae-acbf9228d980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This panda plush is soft, cute, and well-loved by the reviewer's daughter. However, it's a bit small for the price, and there may be better value options available. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "A0wQrekqbird"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HewRdy8ObAcZ",
        "outputId": "c5bc25ad-07a4-4206-a1a6-2c0a0359ce83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A panda plush toy, cheaper than expected, arrived early, and while cute, its size is too small for some customers' liking.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extractive Summarization"
      ],
      "metadata": {
        "id": "r5DVPHtbb111"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to extract relevant information from \\\n",
        "a product review from an ecommerce site to give \\\n",
        "feedback to the Shipping department.\n",
        "\n",
        "From the review below, delimited by triple quotes \\\n",
        "extract the information relevant to shipping and \\\n",
        "delivery. Limit to 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UQPDWtrUb4Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "GiVKmZuyb4Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32671ca8-c048-441a-d63f-0d348912ae68",
        "id": "j5NEy3r9b4Py"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback: The customer received the product a day earlier than expected, which was a positive surprise. Consider offering larger options for the same price to enhance customer satisfaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "awcXiT0kb4Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9cc035a8-d96d-4aa6-afd3-32ea5563c8c2",
        "id": "FPBhWZsAb4Py"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The product arrived a day earlier than expected, allowing the customer to play with it before giving it to their daughter. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**"
      ],
      "metadata": {
        "id": "N0gVVSvhb4Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dfc97a-a0be-455f-c7cd-13d147c8d6bb",
        "id": "SXpsIvR6b4Pz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted value for size; positive early arrival and recipient enjoyment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis"
      ],
      "metadata": {
        "id": "DPGLplBfcDqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_review = \"\"\"\n",
        "worst $10 i‚Äôve spent WHY DID THEY SING\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MYSdE2UkcMAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following movie review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{movie_review}'''\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VhI7twVCcMAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI**"
      ],
      "metadata": {
        "id": "prPP9ELNcMAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f93ce7-6a7c-4f49-bc1c-929863658ec9",
        "id": "eW-GQQHZcMAB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the movie review is negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gemini**"
      ],
      "metadata": {
        "id": "zK3q_FgccMAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ec3f9275-3aae-4c7e-b54c-aaccd5292d90",
        "id": "WuVlrK5HcMAB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the review is **extremely negative**. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **\"worst $10 I‚Äôve spent\"**: This directly expresses dissatisfaction with the value for money.\n",
            "* **\"WHY DID THEY SING\"**: This implies annoyance and frustration, likely indicating the reviewer found the singing aspect of the movie particularly bad. \n",
            "\n",
            "The use of all caps in \"WHY DID THEY SING\" further emphasizes the negative sentiment. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28e52bf-0875-499e-f69a-889e378d10ef",
        "id": "cGprrWgCcMAC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of this movie review is strongly negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation"
      ],
      "metadata": {
        "id": "YhlPgzJueuyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish: \\\n",
        "```Hi, I would like to order a blender```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MFCYdICxewpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_openai(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f63b77-967f-4140-9956-b774f6b39b87",
        "id": "CualoUukewpy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola, me gustar√≠a ordenar una licuadora.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_gemini(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2e78afc2-9d06-4b65-8e9c-6bbc661207d2",
        "id": "6KCW7nSdewpz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola, me gustar√≠a pedir una licuadora. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_hf(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3613b419-6e68-488d-ebfc-96953c00e06f",
        "id": "ToVCeO0lewpz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola, me gustar√≠a pedir una batidora\n",
            "\n",
            "In Spanish, this translation maintains the original meaning and structure. The greeting has been translated to \"Hola,\" which is equivalent to \"Hi\" in English. The rest of the sentence follows a similar construction in Spanish, with ‚Äúme gustar√≠a‚Äù (I would like) being polite and akin to the English phrase, utilizing \"querer\" in a conditional form which translates as \"w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sj72RoLke4k9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}